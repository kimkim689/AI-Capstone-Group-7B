# -*- coding: utf-8 -*-
"""DOE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xNnew__wM8iPnTZjiCfQBpnrD8h7IOz-
"""

import pandas as pd

# Load dataset
data = pd.read_csv('/content/drive/MyDrive/CycleData.csv')

# Calculate the percentage of NULL values in each column
null_percentage = data.isnull().mean()

# Filter out columns where the null percentage is greater than 60%
columns_to_keep = null_percentage[null_percentage < 0.6].index.tolist()

# Keep only the columns that have less than 60% NULL values
data = data[columns_to_keep]

# Filter to include only rows where the cycle type is 'TruckCycle'
# Ensure that the 'Cycle Type' column was not removed due to NULL values before filtering rows
if 'Cycle Type' in data.columns:
    data = data[data['Cycle Type'] == 'TruckCycle']
else:
    print("Filtered dataset does not include 'Cycle Type' due to high null values or it does not exist.")

# Save the filtered data to a new CSV file
data.to_csv('FilteredData_TruckCycle.csv', index=False)

# Print a message about the completion of the filtering
print("Data filtering complete. Here is the snippet of the filtered dataset:")
print(data.head())

import pandas as pd

# Load the dataset
file_path = '/content/FilteredData_TruckCycle.csv'
data = pd.read_csv(file_path)

# Initial filtered attributes focusing on key aspects for fuel consumption prediction
filtered_data = data[['Fuel Used', 'COMPLETEDCYCLEDURATION', 'Payload (kg)', 'Autonomous',
                      'Available SMU Time', 'iMine Operating Hours', 'AT Available Time (iMine)',
                      'Travelling Empty Duration', 'Travelling Full Duration', 'Idle Duration', 'Primary Machine Class Name']]

# One-hot encode the truck models
filtered_data = pd.get_dummies(filtered_data, columns=['Primary Machine Class Name'])

# Display the first few rows of the filtered dataset to verify
print(filtered_data.head())

# Now the dataset includes additional columns for each truck model, which can be used in regression analysis.

import pandas as pd
import statsmodels.api as sm
import numpy as np
# Load the dataset
file_path = '/content/FilteredData_TruckCycle.csv'
data = pd.read_csv(file_path)

# One-hot encode the truck models
data = pd.get_dummies(data, columns=['Primary Machine Class Name'])

# Convert all columns to float, coercing errors and filling NaNs
for column in data.columns:
    data[column] = pd.to_numeric(data[column], errors='coerce')
data.fillna(data.mean(), inplace=True)

# Convert boolean columns to integer to avoid any Statsmodels issues
data['Primary Machine Class Name_CAT 793F CMD'] = data['Primary Machine Class Name_CAT 793F CMD'].astype(int)
data['Primary Machine Class Name_Cat 789C'] = data['Primary Machine Class Name_Cat 789C'].astype(int)

# Ensure no infinite values exist
data.replace([np.inf, -np.inf], np.nan, inplace=True)
data.fillna(data.mean(), inplace=True)

# Define predictors and add a constant for intercept
predictors = ['COMPLETEDCYCLEDURATION', 'Payload (kg)', 'Autonomous', 'Available SMU Time',
              'iMine Operating Hours', 'AT Available Time (iMine)', 'Travelling Empty Duration',
              'Travelling Full Duration', 'Idle Duration',
              'Primary Machine Class Name_CAT 793F CMD', 'Primary Machine Class Name_Cat 789C']
X = sm.add_constant(data[predictors])  # Adding a constant for the intercept

# Dependent variable
y = data['Fuel Used']

# Fit the regression model
model = sm.OLS(y, X).fit()

# Print out the summary of the regression model
print(model.summary())

# Compute the correlation matrix
correlation_matrix = X.iloc[:, 1:].corr()  # Exclude the constant
print(correlation_matrix)

# You might also use variance inflation factor (VIF) to quantify multicollinearity
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_data = pd.DataFrame()
vif_data['feature'] = X.columns[1:]  # Exclude the intercept
vif_data['VIF'] = [variance_inflation_factor(X.values, i+1) for i in range(len(X.columns[1:]))]
print(vif_data)

import pandas as pd
import numpy as np
import statsmodels.api as sm

# Assuming data has already been loaded and processed as before
# Define predictors, excluding 'Autonomous', and add a constant for intercept
predictors = ['COMPLETEDCYCLEDURATION', 'Payload (kg)', 'Available SMU Time',
              'iMine Operating Hours', 'AT Available Time (iMine)', 'Travelling Empty Duration',
              'Travelling Full Duration', 'Idle Duration',
              'Primary Machine Class Name_CAT 793F CMD', 'Primary Machine Class Name_Cat 789C']
X = sm.add_constant(data[predictors])

# Fit the regression model
model = sm.OLS(y, X).fit()

# Print out the summary of the regression model
print(model.summary())

# Recalculate VIFs to check improvements
vif_data = pd.DataFrame()
vif_data['feature'] = X.columns[1:]  # Exclude the intercept
vif_data['VIF'] = [variance_inflation_factor(X.values, i+1) for i in range(len(X.columns[1:]))]
print(vif_data)

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Splitting the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fitting the model on the training data
model_train = sm.OLS(y_train, X_train).fit()

# Predicting on the test data
y_pred = model_train.predict(X_test)

# Calculating the RMSE
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print("Root Mean Squared Error:", rmse)

import matplotlib.pyplot as plt
import seaborn as sns

# Predictions and residuals
y_train_pred = model_train.predict(X_train)
residuals = y_train - y_train_pred

# Plotting residuals
plt.figure(figsize=(10, 6))
plt.scatter(y_train_pred, residuals)
plt.axhline(y=0, color='red', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residuals vs Predicted Values')
plt.show()

# Histogram of the residuals
plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True)
plt.title('Distribution of Residuals')
plt.xlabel('Residuals')
plt.show()

# Q-Q plot for normality check
import scipy.stats as stats
plt.figure(figsize=(10, 6))
stats.probplot(residuals, dist="norm", plot=plt)
plt.title('Q-Q Plot of Residuals')
plt.show()

from statsmodels.stats.outliers_influence import OLSInfluence

# Leverage and influence plot
influence = OLSInfluence(model_train)
fig, ax = plt.subplots(figsize=(10, 6))
influence.plot_influence(ax=ax)
plt.title('Influence Plot')
plt.show()

# Cook's distance to identify potential outliers
fig, ax = plt.subplots(figsize=(10, 6))
influence.plot_index(y_var="cooks", threshold=4 / len(X_train), ax=ax)
plt.title('Cook\'s Distance')
plt.show()

